{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colab\n",
    "# !pip install -qq rasterio timm\n",
    "# !pip install -Uqq fastbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.torch_core import TensorMask, TensorImage\n",
    "import rasterio as rio\n",
    "import timm\n",
    "import torch\n",
    "import fastai\n",
    "from rasterio.enums import Resampling\n",
    "import torch.multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# import SaveModelCallback from fastai\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastai.vision.all import Normalize\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.block import TransformBlock\n",
    "from fastai.vision.core import TensorImage, TensorMask\n",
    "from fastai.vision.augment import RandTransform\n",
    "from fastai.vision.core import default_device\n",
    "import random\n",
    "from functools import partial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce208a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"1.30\"  # Assigns string value to model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training data is needed\n",
    "\n",
    "# import gdown\n",
    "# import zipfile\n",
    "\n",
    "# training_data_zip_path = Path.cwd() / \"training data/training data.zip\"\n",
    "# training_data_zip_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "# url = \"https://drive.google.com/uc?id=1ohuFbG7zV73ZUTIM3ybAlOk87n-nppov\"\n",
    "# gdown.download(url, str(training_data_zip_path), quiet=False)\n",
    "\n",
    "# with zipfile.ZipFile(training_data_zip_path, \"r\") as zip_ref:\n",
    "#     zip_ref.extractall(path=training_data_zip_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "/media/nick/SNEAKERNET/training data/labels_2_3_4_8_V3\n"
     ]
    }
   ],
   "source": [
    "# for colab\n",
    "# path = training_data_zip_path.parent\n",
    "\n",
    "# for local\n",
    "path = Path(\"/media/nick/SNEAKERNET/training data\")\n",
    "\n",
    "label_path = path / \"labels_2_3_4_8_V3\"\n",
    "\n",
    "images_path = path / \"images_2_3_4_8_V3\"\n",
    "print(label_path.exists(), images_path.exists())\n",
    "print(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8f8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0.post200\n",
      "2.7.12\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/mambaforge/envs/c2m/lib/python3.8/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1680542704550/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(fastai.__version__)\n",
    "print(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276a320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enabling this will speed up training but can result in NAN loss\n",
    "fp_16 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all models available in timm\n",
    "# timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"regnety_002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb2659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('regnety_002_v1.30_model', 'regnety_002_v1.30_model_temp')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = (\n",
    "    f\"{model_type}_v{model_version}_model\"  # Assigns string value to model_name\n",
    ")\n",
    "temp_file_name = model_name + \"_temp\"\n",
    "model_name, temp_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421f67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, g, r, nir = 1, 2, 3, 4\n",
    "# how many time steps to use max is 6\n",
    "time_steps = 6\n",
    "# pick the bands you want to use\n",
    "only_use = [g, nir]\n",
    "bands_per_timestep = len(only_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91b35432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limited_band_read_list = []\n",
    "for i in range(time_steps):\n",
    "    for band in only_use:\n",
    "        limited_band_read_list.append(i * 4 + band)\n",
    "limited_band_read_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363bdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(label_path, file_path):\n",
    "    label_path = label_path / file_path.name\n",
    "\n",
    "    return label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ada84fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to get img list to use excluding the bad images\n",
    "def get_image_files_custom(source, p=False):\n",
    "    return list(source.glob(\"[!.]*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b9d2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11647"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_names = list(get_image_files_custom(images_path))\n",
    "len(f_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "426127c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/media/nick/SNEAKERNET/training data/images_2_3_4_8_V3/853_OSM_80.tif')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19ab0cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_paths = []\n",
    "for img in f_names:\n",
    "    if \"Validation\" in img.name:\n",
    "        validation_paths.append(img)\n",
    "\n",
    "len(validation_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6242cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_file(x, validation_paths):\n",
    "    return x in validation_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b5c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switcheroo(RandTransform):\n",
    "    \"Randomly switch the order of the time steps, keeping the band order the same\"\n",
    "\n",
    "    split_idx, order = 0, 2\n",
    "\n",
    "    def __init__(self, p=1, bands_per_timestep=2, time_steps=3):\n",
    "        super().__init__(p=p)\n",
    "        self.bands_per_timestep = bands_per_timestep\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def encodes(self, x: (TensorImage)):\n",
    "        new_time_step_order = torch.randperm(self.time_steps)\n",
    "        new_order = [\n",
    "            (i * self.bands_per_timestep) + j\n",
    "            for i in new_time_step_order\n",
    "            for j in range(self.bands_per_timestep)\n",
    "        ]\n",
    "        return x[:, new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2b9fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchRot90(RandTransform):\n",
    "    \"Rotate image and mask by 0, 90, 180, or 270 degrees\"\n",
    "\n",
    "    split_idx, order = 0, 2\n",
    "\n",
    "    def __init__(self, p=1):\n",
    "        super().__init__(p=p)\n",
    "        self.rots = 0\n",
    "\n",
    "    def before_call(self, b, split_idx):\n",
    "        if random.random() < self.p:\n",
    "            self.rot = random.choice([0, 1, 2, 3])\n",
    "        else:\n",
    "            self.rot = 0\n",
    "\n",
    "    def encodes(self, x: (TensorImage, TensorMask)):\n",
    "        return x.rot90(self.rot, [-2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cbbfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_mask(img_path, img_size):\n",
    "    with rio.open(img_path) as src:\n",
    "        raw_bands = src.read(\n",
    "            1, out_shape=(img_size, img_size), resampling=Resampling.nearest\n",
    "        )\n",
    "    return TensorMask(torch.from_numpy(raw_bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c3d69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fc9ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_img(img_path, img_size):\n",
    "    if img_path in image_cache:\n",
    "        tensor_img = image_cache[img_path]\n",
    "        if tensor_img.shape[-1] == img_size:\n",
    "            return tensor_img\n",
    "    with rio.open(img_path) as src:\n",
    "        raw_bands = src.read(limited_band_read_list, out_shape=(img_size, img_size))\n",
    "\n",
    "    tensor_img = TensorImage(torch.from_numpy(raw_bands.astype(\"float16\")))\n",
    "    if fp_16:\n",
    "        tensor_img = tensor_img.half()\n",
    "\n",
    "    tensor_img = tensor_img.cuda()\n",
    "\n",
    "    image_cache[img_path] = tensor_img\n",
    "    return tensor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74682192",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mopen_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m, in \u001b[0;36mopen_img\u001b[0;34m(img_path, img_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fp_16:\n\u001b[1;32m     11\u001b[0m     tensor_img \u001b[38;5;241m=\u001b[39m tensor_img\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[0;32m---> 13\u001b[0m tensor_img \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m image_cache[img_path] \u001b[38;5;241m=\u001b[39m tensor_img\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_img\n",
      "File \u001b[0;32m~/mambaforge/envs/c2m/lib/python3.8/site-packages/fastai/torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 382\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/c2m/lib/python3.8/site-packages/torch/_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/mambaforge/envs/c2m/lib/python3.8/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "open_img(f_names[0], 256).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1372099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_means = []\n",
    "# all_stds = []\n",
    "# for i in tqdm(f_names):\n",
    "#     image_tensor = open_img(i, 256) / 32767\n",
    "#     all_means.append(image_tensor.mean((1, 2)).tolist())\n",
    "#     all_stds.append(image_tensor.std((1, 2)).tolist())\n",
    "# all_stds = np.array(all_stds).mean((0))\n",
    "# all_means = np.array(all_means).mean((0))\n",
    "# # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = np.array(\n",
    "    [\n",
    "        0.09320524,\n",
    "        0.09936677,\n",
    "        0.09359581,\n",
    "        0.09989304,\n",
    "        0.09392498,\n",
    "        0.0994415,\n",
    "        0.09318926,\n",
    "        0.09834657,\n",
    "        0.09105494,\n",
    "        0.09607462,\n",
    "        0.09178863,\n",
    "        0.09679132,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stds = np.array(\n",
    "    [\n",
    "        0.02172433,\n",
    "        0.02760383,\n",
    "        0.02274428,\n",
    "        0.02833729,\n",
    "        0.02223172,\n",
    "        0.0276719,\n",
    "        0.02222958,\n",
    "        0.02731097,\n",
    "        0.02183141,\n",
    "        0.02698776,\n",
    "        0.02132447,\n",
    "        0.02619315,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build datablock\n",
    "def build_dblock(img_size):\n",
    "    open_img_partial = partial(open_img, img_size=img_size)\n",
    "    open_mask_partial = partial(open_mask, img_size=img_size)\n",
    "    lable_func_partial = partial(label_func, label_path)\n",
    "\n",
    "    label_block = TransformBlock(open_mask_partial)\n",
    "    dblock = DataBlock(\n",
    "        blocks=(TransformBlock(open_img_partial), label_block),\n",
    "        get_items=get_image_files_custom,\n",
    "        get_y=lable_func_partial,\n",
    "        splitter=FuncSplitter(lambda x: is_valid_file(x, validation_paths)),\n",
    "        batch_tfms=[\n",
    "            IntToFloatTensor(32767, 1),\n",
    "            *aug_transforms(\n",
    "                flip_vert=True,\n",
    "                max_rotate=0,\n",
    "                max_zoom=0.2,\n",
    "                max_lighting=0.2,\n",
    "                max_warp=0,\n",
    "                p_affine=0,\n",
    "                p_lighting=0.2,\n",
    "                size=img_size,\n",
    "            ),\n",
    "            BatchRot90(),\n",
    "            # Switcheroo(bands_per_timestep=bands_per_timestep, time_steps=time_steps),\n",
    "            Normalize.from_stats(mean=all_means, std=all_stds),\n",
    "        ],\n",
    "    )\n",
    "    return dblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0043d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = build_dblock(256).dataloaders(images_path, bs=16, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba39244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9497fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm_model = partial(\n",
    "    timm.create_model,\n",
    "    model_type,\n",
    "    pretrained=True,\n",
    "    in_chans=dl.one_batch()[0].shape[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = MSELossFlat()\n",
    "n_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = unet_learner(\n",
    "    dl, timm_model, pretrained=True, loss_func=loss_func, n_out=n_out\n",
    ")\n",
    "if fp_16:\n",
    "    print(\"Converting to FP16\")\n",
    "    learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc847d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "    SaveModelCallback(monitor=\"valid_loss\", fname=model_name, with_opt=True),\n",
    "    ShowGraphCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fine_tune(\n",
    "    freeze_epochs=10,\n",
    "    epochs=30,\n",
    "    cbs=cbs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload best model\n",
    "learner.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f346cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_numb = 1\n",
    "p = learner.predict(validation_paths[img_numb], with_input=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 7))  # 1 row, 3 columns\n",
    "axes[0].imshow(p[0].numpy()[2])\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(p[1].numpy()[0] > 0)\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(p[1].numpy()[0])\n",
    "axes[2].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    learner.model.to(\"cpu\"), open(Path.cwd() / f\"models/{model_name}.pkl\", \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{model_name}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30bbce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
