{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e815a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.torch_core import TensorMask, TensorImage\n",
    "\n",
    "# from fastai.callback.core import Callback\n",
    "# from fastai.data.core import DataLoaders\n",
    "import rasterio as rio\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import fastai\n",
    "from rasterio.enums import Resampling\n",
    "import torch.multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training data here\n",
    "# https://drive.google.com/drive/folders/1Z60g3SxBiSTEZzuHDPOUuNL7I_Mg_dGq?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(fastai.__version__)\n",
    "print(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96add3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of dictionaries containing model types and batch sizes to train\n",
    "model_details = {\"model_type\": \"regnety_006\", \"fp_16\": True, \"lr\": 1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details[\"model_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b06ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"1.10\"  # Assigns string value to model_version\n",
    "model_name = f\"{model_details['model_type']}_v{model_version}_model\"  # Assigns string value to model_name\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40969ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b917e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limited_band_read_list = [1, 2, 3, 4, 5, 6]\n",
    "limited_band_read_list = list(range(1, 4 * time_steps + 1))\n",
    "limited_band_read_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_band_read_list = [\n",
    "    # 1,\n",
    "    2,\n",
    "    # 3,\n",
    "    4,\n",
    "    #  5,\n",
    "    6,\n",
    "    # 7,\n",
    "    8,\n",
    "    #  9,\n",
    "    10,\n",
    "    # 11,\n",
    "    12,\n",
    "    #  13,\n",
    "    14,\n",
    "    # 15,\n",
    "    16,\n",
    "    #  17,\n",
    "    18,\n",
    "    # 19,\n",
    "    20,\n",
    "    #  21,\n",
    "    22,\n",
    "    # 23,\n",
    "    24,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73cdbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_per_timestep = int(len(limited_band_read_list) / time_steps)\n",
    "bands_per_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0525399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to image and mask directories\n",
    "\n",
    "path = Path.cwd() / \"training data\"\n",
    "label_path = path / \"labels_2_3_4_8_V3\"\n",
    "images_path = path / \"images_2_3_4_8_V3\"\n",
    "print(label_path.exists(), images_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = [64, 32, 16]\n",
    "bs = [4, 2, 1]\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363bdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(label_path, file_path):\n",
    "    label_path = label_path / file_path.name\n",
    "\n",
    "    return label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada84fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to get img list to use excluding the bad images\n",
    "def get_image_files_custom(source, p=False):\n",
    "    return list(source.glob(\"[!.]*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = list(get_image_files_custom(images_path))\n",
    "len(f_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426127c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_paths = []\n",
    "for type in [\"OSM\", \"NZ\", \"Aus\"]:\n",
    "    for i in range(15):\n",
    "        file = images_path / f\"{i}_{type}_80.tif\"\n",
    "        if file.exists():\n",
    "            validation_paths.append(file)\n",
    "            # print(file.exists())\n",
    "    # validation_paths.append()\n",
    "len(validation_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_file(x, validation_paths):\n",
    "    return x in validation_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5af642",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(12, 128, 128).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switcheroo(RandTransform):\n",
    "    \"Randomly switch the order of the time steps, keeping the band order the same\"\n",
    "\n",
    "    split_idx, order = 0, 2\n",
    "\n",
    "    def __init__(self, p=1, bands_per_timestep=2, time_steps=3):\n",
    "        super().__init__(p=p)\n",
    "        self.bands_per_timestep = bands_per_timestep\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def encodes(self, x: (TensorImage)):\n",
    "        new_time_step_order = torch.randperm(self.time_steps)\n",
    "        new_order = [\n",
    "            (i * self.bands_per_timestep) + j\n",
    "            for i in new_time_step_order\n",
    "            for j in range(self.bands_per_timestep)\n",
    "        ]\n",
    "        return x[:, new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchRot90(RandTransform):\n",
    "    \"Rotate image and mask by 0, 90, 180, or 270 degrees\"\n",
    "    split_idx, order = 0, 2\n",
    "\n",
    "    def __init__(self, p=1):\n",
    "        super().__init__(p=p)\n",
    "        self.rots = 0\n",
    "\n",
    "    def before_call(self, b, split_idx):\n",
    "        if random.random() < self.p:\n",
    "            self.rot = random.choice([0, 1, 2, 3])\n",
    "        else:\n",
    "            self.rot = 0\n",
    "\n",
    "    def encodes(self, x: (TensorImage, TensorMask)):\n",
    "        return x.rot90(self.rot, [-2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_mask(img_path, img_size):\n",
    "    with rio.open(img_path) as src:\n",
    "        raw_bands = src.read(\n",
    "            1, out_shape=(img_size, img_size), resampling=Resampling.nearest\n",
    "        )\n",
    "    return TensorMask(torch.from_numpy(raw_bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf60fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f60bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_img(img_path, img_size):\n",
    "    if img_path in image_cache:\n",
    "        return image_cache[img_path]\n",
    "    with rio.open(img_path) as src:\n",
    "        raw_bands = src.read(limited_band_read_list, out_shape=(img_size, img_size))\n",
    "    tensor_img = (\n",
    "        TensorImage(torch.from_numpy(raw_bands.astype(\"float16\"))).half().to(device)\n",
    "    )\n",
    "    if fp16:\n",
    "        tensor_img = (TensorImage(torch.from_numpy(raw_bands.astype(\"float16\")))).half()\n",
    "    else:\n",
    "        tensor_img = TensorImage(torch.from_numpy(raw_bands.astype(\"float32\")))\n",
    "\n",
    "    tensor_img = tensor_img.to(device)\n",
    "\n",
    "    image_cache[img_path] = tensor_img\n",
    "    return tensor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = open_img(f_names[0], 128)\n",
    "band_per_step = int(test_img.shape[0] / time_steps)\n",
    "band_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1372099",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = []\n",
    "all_stds = []\n",
    "for i in tqdm(f_names):\n",
    "    image_tensor = open_img(i, 128) / 32767\n",
    "    all_means.append(image_tensor.mean((1, 2)).tolist())\n",
    "    all_stds.append(image_tensor.std((1, 2)).tolist())\n",
    "all_stds = np.array(all_stds).mean((0))\n",
    "all_means = np.array(all_means).mean((0))\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "for band in range(1, band_per_step + 1):\n",
    "    print(band)\n",
    "    means.append(all_stds[band::band_per_step].mean())\n",
    "    stds.append(all_means[band::band_per_step].mean())\n",
    "\n",
    "extended_means = []\n",
    "extended_stds = []\n",
    "for i in range(time_steps):\n",
    "    extended_means.extend(means)\n",
    "    extended_stds.extend(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build datablock\n",
    "def build_dblock(img_size):\n",
    "    open_img_partial = partial(open_img, img_size=img_size)\n",
    "    open_mask_partial = partial(open_mask, img_size=img_size)\n",
    "    lable_func_partial = partial(label_func, label_path)\n",
    "\n",
    "    dblock = DataBlock(\n",
    "        blocks=(\n",
    "            TransformBlock(open_img_partial),\n",
    "            TransformBlock(open_mask_partial),\n",
    "            # MaskBlock(),\n",
    "        ),\n",
    "        get_items=get_image_files_custom,\n",
    "        get_y=lable_func_partial,\n",
    "        splitter=FuncSplitter(lambda x: is_valid_file(x, validation_paths)),\n",
    "        batch_tfms=[\n",
    "            IntToFloatTensor(32767, 1),\n",
    "            *aug_transforms(\n",
    "                flip_vert=True,\n",
    "                max_rotate=0,\n",
    "                max_zoom=0.2,\n",
    "                max_lighting=0.2,\n",
    "                max_warp=0,\n",
    "                p_affine=0,\n",
    "                p_lighting=0.2,\n",
    "                size=img_size,\n",
    "            ),\n",
    "            BatchRot90(),\n",
    "            Switcheroo(bands_per_timestep=bands_per_timestep, time_steps=time_steps),\n",
    "            Normalize.from_stats(mean=all_means, std=all_stds),\n",
    "        ],\n",
    "    )\n",
    "    return dblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1a0a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dblock = build_dblock(128)\n",
    "\n",
    "dl = dblock.dataloaders(\n",
    "    size=128,\n",
    "    source=images_path,\n",
    "    bs=2,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba39244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9497fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ob[1].cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm_model = partial(\n",
    "    timm.create_model,\n",
    "    model_details[\"model_type\"],\n",
    "    pretrained=True,\n",
    "    in_chans=dl.one_batch()[0].shape[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = unet_learner(\n",
    "    dl, timm_model, pretrained=True, loss_func=MSELossFlat(), n_out=1\n",
    ")\n",
    "if fp16:\n",
    "    learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fine_tune(\n",
    "    freeze_epochs=5,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f346cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_numb = 1\n",
    "p = learner.predict(validation_paths[img_numb], with_input=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 7))  # 1 row, 3 columns\n",
    "axes[0].imshow(p[0].numpy()[2])\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(p[1].numpy()[0] > 0)\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(p[1].numpy()[0])\n",
    "axes[2].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(learner.model, open(f\"{model_name}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{model_name}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d0e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
