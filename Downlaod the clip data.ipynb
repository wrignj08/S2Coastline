{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pystac.extensions.eo import EOExtension as eo\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "import pyproj\n",
    "from tqdm.auto import tqdm\n",
    "from rasterio import Affine\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import transform\n",
    "from pyproj import Transformer\n",
    "from multiprocess import Pool\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import time\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the world tide api key, let me know if you need it\n",
    "planetary_computer_key_file = Path.cwd() / \"planitary_computer_key.txt\"\n",
    "planetary_computer_api_key = planetary_computer_key_file.read_text().strip()\n",
    "os.environ[\"PC_SDK_SUBSCRIPTION_KEY\"] = planetary_computer_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"OSM\"\n",
    "# source = \"Aus\"\n",
    "# source = \"NZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\n",
    "    \"/Users/Nick/Library/Mobile Documents/com~apple~CloudDocs/QGIS/Coastline training data v2/\"\n",
    ")\n",
    "data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "vector_points_path = data_dir / f\"{source}/{source} training data.gpkg\"\n",
    "print(vector_points_path.exists())\n",
    "vector_points = gpd.read_file(vector_points_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ocean_path = data_dir / f\"{source}/{source} polygons.gpkg\"\n",
    "print(ocean_path.exists())\n",
    "coastline_path = data_dir / f\"{source}/{source} lines.gpkg\"\n",
    "print(coastline_path.exists())\n",
    "prefix = f\"{source}_80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = Path.cwd() / \"training data\" / \"images_2_3_4_8_V3\"\n",
    "sar_path = Path.cwd() / \"training data\" / \"SAR_V3\"\n",
    "labels_path = Path.cwd() / \"training data\" / \"labels_2_3_4_8_V3\"\n",
    "labels_path.mkdir(exist_ok=True, parents=True)\n",
    "images_path.mkdir(exist_ok=True, parents=True)\n",
    "sar_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "time_steps = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prods(point, time_of_interest=\"2022-01-01/2023-01-01\"):\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        intersects=point,\n",
    "        datetime=time_of_interest,\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 80}},\n",
    "    )\n",
    "    items = search.item_collection()\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wgs_point_to_local_box(product, wgs_point, vector_data_crs_number):\n",
    "    local_crs_number = product.properties[\"proj:epsg\"]\n",
    "    source_crs = pyproj.CRS(f\"EPSG:{vector_data_crs_number}\")\n",
    "    target_crs = pyproj.CRS(f\"EPSG:{local_crs_number}\")\n",
    "    transformer = pyproj.Transformer.from_crs(source_crs, target_crs, always_xy=True)\n",
    "    x, y = wgs_point.x, wgs_point.y\n",
    "    x_transformed, y_transformed = transformer.transform(x, y)\n",
    "    point_utm = Point(x_transformed, y_transformed)\n",
    "    point_buffer = point_utm.buffer(2560 / 2)\n",
    "    return point_buffer.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4326"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get epsg code\n",
    "vector_data_crs_number = vector_points.crs.to_epsg()\n",
    "vector_data_crs_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_bands = time_steps * len(bands)\n",
    "total_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in tqdm(vector_points.iterrows(), total=len(vector_points)):\n",
    "def downlaod_image(row):\n",
    "    try:\n",
    "        wgs_point = row[1].geometry\n",
    "\n",
    "        if wgs_point is None:\n",
    "            return\n",
    "\n",
    "        export_name = f\"{row[0]}_{prefix}.tif\"\n",
    "        export_path = images_path / export_name\n",
    "\n",
    "        if export_path.stem in skip_list:\n",
    "            return\n",
    "\n",
    "        if export_path.exists():\n",
    "            return\n",
    "\n",
    "        search_point = {\"type\": \"Point\", \"coordinates\": [wgs_point.x, wgs_point.y]}\n",
    "\n",
    "        products = find_prods(search_point)\n",
    "        arrays = []\n",
    "        # print(products)\n",
    "        for product in products:\n",
    "            # print(product.id)\n",
    "            b_box = wgs_point_to_local_box(product, wgs_point, vector_data_crs_number)\n",
    "            band_arrays = []\n",
    "            skip = False\n",
    "            for band in bands:\n",
    "                if skip:\n",
    "                    continue\n",
    "                # time.sleep(2)\n",
    "                with rio.open(product.assets[band].href) as src:\n",
    "                    window = rio.windows.from_bounds(*b_box, src.transform)\n",
    "\n",
    "                    array = src.read(1, window=window)\n",
    "                    if array.shape != (256, 256):\n",
    "                        print(f\"Array shape is {array.shape} for {export_name}\")\n",
    "                        skip = True\n",
    "                        continue\n",
    "                    transform = rio.windows.transform(window, transform=src.transform)\n",
    "                    profile = src.profile.copy()\n",
    "                    if band == bands[0]:\n",
    "                        # print(np.count_nonzero(array == 0))\n",
    "                        if np.count_nonzero(array == 0) > 100:\n",
    "                            skip = True\n",
    "                            continue\n",
    "\n",
    "                    band_arrays.append(array)\n",
    "\n",
    "            for band_array in band_arrays:\n",
    "                arrays.append(band_array)\n",
    "\n",
    "            if len(arrays) == total_bands:\n",
    "                break\n",
    "\n",
    "        if len(arrays) != total_bands:\n",
    "            print(f\"Could not find 3 images for {export_name}\")\n",
    "            time.sleep(2)\n",
    "            return\n",
    "        profile.update(\n",
    "            {\n",
    "                \"height\": array.shape[0],\n",
    "                \"width\": array.shape[1],\n",
    "                \"transform\": transform,\n",
    "                \"count\": total_bands,\n",
    "            }\n",
    "        )\n",
    "        with rio.open(export_path, \"w\", **profile) as dst:\n",
    "            dst.write(np.array(arrays))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Failed to download {export_name}\")\n",
    "        time.sleep(2)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_points = vector_points.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_list = [\n",
    "    \"614_OSM_80\",\n",
    "    \"611_OSM_80\",\n",
    "    \"579_OSM_80\",\n",
    "    \"577_OSM_80\",\n",
    "    \"554_OSM_80\",\n",
    "    \"550_OSM_80\",\n",
    "    \"536_OSM_80\",\n",
    "    \"533_OSM_80\",\n",
    "    \"531_OSM_80\",\n",
    "    \"526_OSM_80\",\n",
    "    \"523_OSM_80\",\n",
    "    \"509_OSM_80\",\n",
    "    \"490_OSM_80\",\n",
    "    \"478_OSM_80\",\n",
    "    \"466_OSM_80\",\n",
    "    \"465_OSM_80\",\n",
    "    \"462_OSM_80\",\n",
    "    \"797_OSM_80\",\n",
    "    \"798_OSM_80\",\n",
    "    \"791_OSM_80\",\n",
    "    \"777_OSM_80\",\n",
    "    \"775_OSM_80\",\n",
    "    \"758_OSM_80\",\n",
    "    \"716_OSM_80\",\n",
    "    \"706_OSM_80\",\n",
    "    \"691_OSM_80\",\n",
    "    \"325_OSM_80\",\n",
    "    \"355_OSM_80\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:39<00:00, 20.27it/s]\n"
     ]
    }
   ],
   "source": [
    "def worker(i):\n",
    "    if i[0] not in skip_list:\n",
    "        downlaod_image(i)\n",
    "\n",
    "\n",
    "# Number of threads you want to run in parallel\n",
    "num_threads = 8\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    list(tqdm(executor.map(worker, vector_points.iterrows()), total=len(vector_points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 56/90 [00:04<00:02, 12.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Nick/Documents/S2Coastline/Downlaod the clip data.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(vector_points\u001b[39m.\u001b[39miterrows(), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(vector_points)):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m i[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m skip_list:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         downlaod_image(i)\n",
      "\u001b[1;32m/Users/Nick/Documents/S2Coastline/Downlaod the clip data.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# time.sleep(2)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mwith\u001b[39;00m rio\u001b[39m.\u001b[39;49mopen(product\u001b[39m.\u001b[39;49massets[band]\u001b[39m.\u001b[39;49mhref) \u001b[39mas\u001b[39;00m src:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     window \u001b[39m=\u001b[39m rio\u001b[39m.\u001b[39mwindows\u001b[39m.\u001b[39mfrom_bounds(\u001b[39m*\u001b[39mb_box, src\u001b[39m.\u001b[39mtransform)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Nick/Documents/S2Coastline/Downlaod%20the%20clip%20data.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     array \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mread(\u001b[39m1\u001b[39m, window\u001b[39m=\u001b[39mwindow)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/gis_311/lib/python3.11/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/gis_311/lib/python3.11/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[39m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[39m=\u001b[39m DatasetReader(path, driver\u001b[39m=\u001b[39;49mdriver, sharing\u001b[39m=\u001b[39;49msharing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[39m=\u001b[39m get_writer_for_path(path, driver\u001b[39m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[39m=\u001b[39mdriver, sharing\u001b[39m=\u001b[39msharing, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:314\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/gis_311/lib/python3.11/site-packages/rasterio/_path.py:89\u001b[0m, in \u001b[0;36m_ParsedPath.name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m             path \u001b[39m=\u001b[39m parts\u001b[39m.\u001b[39mnetloc \u001b[39m+\u001b[39m path\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m _ParsedPath(path, archive, scheme)\n\u001b[0;32m---> 89\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     91\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The parsed path's original URI\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheme:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in tqdm(vector_points.iterrows(), total=len(vector_points)):\n",
    "#     if i[0] not in skip_list:\n",
    "#         downlaod_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_client = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sar(point):\n",
    "    search = stac_client.search(\n",
    "        collections=[\"sentinel-1-rtc\"],\n",
    "        intersects=point,\n",
    "    )\n",
    "    items = search.get_all_items()\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downlaod_s1_rtc(row):\n",
    "    try:\n",
    "        wgs_point = row[1].geometry\n",
    "\n",
    "        if wgs_point is None:\n",
    "            return\n",
    "\n",
    "        export_name = f\"{row[0]}_{prefix}.tif\"\n",
    "        export_path = sar_path / export_name\n",
    "\n",
    "        if export_path.exists():\n",
    "            return\n",
    "\n",
    "        search_point = {\"type\": \"Point\", \"coordinates\": [wgs_point.x, wgs_point.y]}\n",
    "\n",
    "        products = search_sar(search_point)\n",
    "\n",
    "        skip = False\n",
    "        for product in products:\n",
    "            if not skip:\n",
    "                product = planetary_computer.sign(product)\n",
    "                b_box = wgs_point_to_local_box(\n",
    "                    product, wgs_point, vector_data_crs_number\n",
    "                )\n",
    "                with rio.open(product.assets[\"vh\"].href) as src:\n",
    "                    window = rio.windows.from_bounds(*b_box, src.transform)\n",
    "\n",
    "                    array = src.read(1, window=window)\n",
    "\n",
    "                    transform = rio.windows.transform(window, transform=src.transform)\n",
    "                    profile = src.profile.copy()\n",
    "                    if array.shape == (256, 256):\n",
    "                        if np.count_nonzero(array == 0) < 100:\n",
    "                            skip = True\n",
    "        if skip:\n",
    "            profile.update(\n",
    "                {\n",
    "                    \"height\": array.shape[0],\n",
    "                    \"width\": array.shape[1],\n",
    "                    \"transform\": transform,\n",
    "                    \"count\": 1,\n",
    "                }\n",
    "            )\n",
    "            with rio.open(export_path, \"w\", **profile) as dst:\n",
    "                dst.write(np.array(array), 1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Failed to download {export_name}\")\n",
    "        time.sleep(2)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/900 [00:00<?, ?it/s]/usr/local/Caskroom/miniforge/base/envs/gis_311/lib/python3.11/site-packages/pystac_client/item_search.py:841: FutureWarning: get_all_items() is deprecated, use item_collection() instead.\n",
      "  warnings.warn(\n",
      "  2%|▏         | 20/900 [00:18<09:34,  1.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vh'\n",
      "Failed to download 20_Aus_80.tif\n",
      "'vh'\n",
      "Failed to download 23_Aus_80.tif\n",
      "'vh'\n",
      "Failed to download 22_Aus_80.tif\n",
      "'vh'\n",
      "Failed to download 21_Aus_80.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 199/900 [01:39<05:28,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vh'\n",
      "Failed to download 203_Aus_80.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 231/900 [01:52<04:06,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vh'\n",
      "Failed to download 233_Aus_80.tif\n",
      "'vh'\n",
      "Failed to download 234_Aus_80.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 641/900 [04:47<01:44,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vh'\n",
      "Failed to download 644_Aus_80.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [06:52<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def worker(i):\n",
    "    if i[0] not in skip_list:\n",
    "        downlaod_s1_rtc(i)\n",
    "\n",
    "\n",
    "# Number of threads you want to run in parallel\n",
    "num_threads = 8\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    list(tqdm(executor.map(worker, vector_points.iterrows()), total=len(vector_points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterise(args):\n",
    "    if args is None:\n",
    "        return\n",
    "    (\n",
    "        label_export_path,\n",
    "        coastline_lines_clipped,\n",
    "        clipped_gdf,\n",
    "        profile,\n",
    "        array_transform,\n",
    "        max_dist,\n",
    "    ) = args\n",
    "    if label_export_path.exists():\n",
    "        return\n",
    "    clipped_gdf[\"geometry\"] = clipped_gdf[\"geometry\"].buffer(0)\n",
    "    array = np.zeros((profile[\"height\"], profile[\"width\"]), dtype=np.float32)\n",
    "    for row in range(profile[\"height\"]):\n",
    "        for col in range(profile[\"width\"]):\n",
    "            x, y = array_transform * (col + 0.5, row + 0.5)\n",
    "            point = Point(x, y)\n",
    "\n",
    "            if len(coastline_lines_clipped) == 0:\n",
    "                min_distance = max_dist\n",
    "\n",
    "            else:\n",
    "                min_distance = min(\n",
    "                    geom.distance(point) for geom in coastline_lines_clipped[\"geometry\"]\n",
    "                )\n",
    "\n",
    "            if min_distance > max_dist:\n",
    "                min_distance = max_dist\n",
    "            min_distance = sqrt(min_distance)\n",
    "            if clipped_gdf.intersects(point).any():\n",
    "                array[row, col] = -min_distance\n",
    "            else:\n",
    "                array[row, col] = min_distance\n",
    "\n",
    "    profile.update({\"count\": 1, \"dtype\": \"float32\", \"compress\": \"lzw\"})\n",
    "\n",
    "    with rio.open(label_export_path, \"w\", **profile) as dst:\n",
    "        dst.write(array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label(image, coastline_lines, ocean_polygons, max_dist=50):\n",
    "    try:\n",
    "        label_export_path = labels_path / image.name\n",
    "\n",
    "        if label_export_path.exists():\n",
    "            return\n",
    "\n",
    "        with rio.open(image) as src:\n",
    "            pixel_size = src.transform[0]\n",
    "            extent = src.bounds\n",
    "            raster_poly = box(*extent)\n",
    "            raster_crs = src.crs\n",
    "            profile = src.profile.copy()\n",
    "\n",
    "        transformer = Transformer.from_crs(\n",
    "            raster_crs, ocean_polygons.crs, always_xy=True\n",
    "        )\n",
    "        reprojected_polygon = transform(transformer.transform, raster_poly)\n",
    "\n",
    "        clipped_gdf = (\n",
    "            gpd.clip(ocean_polygons, reprojected_polygon).dissolve().to_crs(raster_crs)\n",
    "        )\n",
    "\n",
    "        coastline_lines_clipped = gpd.clip(coastline_lines, reprojected_polygon).to_crs(\n",
    "            raster_crs\n",
    "        )\n",
    "\n",
    "        minx, miny, maxx, maxy = extent\n",
    "        array_transform = Affine.translation(minx, maxy) * Affine.scale(\n",
    "            pixel_size, -pixel_size\n",
    "        )\n",
    "        args = (\n",
    "            label_export_path,\n",
    "            coastline_lines_clipped,\n",
    "            clipped_gdf,\n",
    "            profile,\n",
    "            array_transform,\n",
    "            max_dist,\n",
    "        )\n",
    "        #\n",
    "        return args\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Failed to make label for {image.name}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = list(images_path.glob(f\"*{prefix}.tif\"))\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_polygons = gpd.read_file(ocean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline = gpd.read_file(coastline_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 783/783 [02:35<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "args_list = []\n",
    "for image in tqdm(images):\n",
    "    args_list.append(\n",
    "        make_label(image, coastline_lines=coastline, ocean_polygons=ocean_polygons)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 783/783 [16:19<00:00,  1.25s/it]  \n"
     ]
    }
   ],
   "source": [
    "with Pool() as p:\n",
    "    list(tqdm(p.imap(rasterise, args_list), total=len(args_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images_path.glob(\"*.tif\")\n",
    "sars = sar_path.glob(\"*.tif\")\n",
    "lebels = labels_path.glob(\"*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [00:00, 10923.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing SAR for 563_OSM_80.tif\n",
      "Missing SAR for 440_OSM_80.tif\n",
      "Missing SAR for 415_OSM_80.tif\n",
      "Missing SAR for 422_OSM_80.tif\n",
      "Missing SAR for 548_OSM_80.tif\n",
      "Missing SAR for 121_OSM_80.tif\n",
      "Missing SAR for 28_OSM_80.tif\n",
      "Missing SAR for 409_OSM_80.tif\n",
      "Missing SAR for 20_Aus_80.tif\n",
      "Missing SAR for 418_OSM_80.tif\n",
      "Missing SAR for 130_OSM_80.tif\n",
      "Missing SAR for 652_OSM_80.tif\n",
      "Missing SAR for 559_OSM_80.tif\n",
      "Missing SAR for 433_OSM_80.tif\n",
      "Missing SAR for 25_OSM_80.tif\n",
      "Missing SAR for 451_OSM_80.tif\n",
      "Missing SAR for 545_OSM_80.tif\n",
      "Missing SAR for 210_OSM_80.tif\n",
      "Missing SAR for 657_OSM_80.tif\n",
      "Missing SAR for 660_OSM_80.tif\n",
      "Missing SAR for 448_OSM_80.tif\n",
      "Missing SAR for 209_OSM_80.tif\n",
      "Missing SAR for 129_OSM_80.tif\n",
      "Missing SAR for 436_OSM_80.tif\n",
      "Missing SAR for 445_OSM_80.tif\n",
      "Missing SAR for 551_OSM_80.tif\n",
      "Missing SAR for 427_OSM_80.tif\n",
      "Missing SAR for 31_OSM_80.tif\n",
      "Missing SAR for 410_OSM_80.tif\n",
      "Missing label for 831_Aus_80.tif\n",
      "Missing SAR for 676_OSM_80.tif\n",
      "Missing SAR for 195_OSM_80.tif\n",
      "Missing SAR for 556_OSM_80.tif\n",
      "Missing SAR for 561_OSM_80.tif\n",
      "Missing SAR for 442_OSM_80.tif\n",
      "Missing SAR for 420_OSM_80.tif\n",
      "Missing SAR for 644_Aus_80.tif\n",
      "Missing SAR for 36_OSM_80.tif\n",
      "Missing SAR for 417_OSM_80.tif\n",
      "Missing SAR for 27_OSM_80.tif\n",
      "Missing SAR for 431_OSM_80.tif\n",
      "Missing SAR for 453_OSM_80.tif\n",
      "Missing SAR for 212_OSM_80.tif\n",
      "Missing SAR for 547_OSM_80.tif\n",
      "Missing SAR for 650_OSM_80.tif\n",
      "Missing SAR for 22_Aus_80.tif\n",
      "Missing SAR for 434_OSM_80.tif\n",
      "Missing SAR for 22_OSM_80.tif\n",
      "Missing SAR for 655_OSM_80.tif\n",
      "Missing SAR for 428_OSM_80.tif\n",
      "Missing SAR for 203_Aus_80.tif\n",
      "Missing SAR for 439_OSM_80.tif\n",
      "Missing SAR for 126_OSM_80.tif\n",
      "Missing SAR for 447_OSM_80.tif\n",
      "Missing SAR for 564_OSM_80.tif\n",
      "Missing SAR for 553_OSM_80.tif\n",
      "Missing SAR for 412_OSM_80.tif\n",
      "Missing SAR for 658_OSM_80.tif\n",
      "Missing SAR for 425_OSM_80.tif\n",
      "Missing SAR for 656_OSM_80.tif\n",
      "Missing SAR for 449_OSM_80.tif\n",
      "Missing SAR for 208_OSM_80.tif\n",
      "Missing SAR for 21_OSM_80.tif\n",
      "Missing SAR for 437_OSM_80.tif\n",
      "Missing SAR for 128_OSM_80.tif\n",
      "Missing SAR for 444_OSM_80.tif\n",
      "Missing SAR for 344_OSM_80.tif\n",
      "Missing SAR for 426_OSM_80.tif\n",
      "Missing SAR for 411_OSM_80.tif\n",
      "Missing SAR for 562_OSM_80.tif\n",
      "Missing SAR for 555_OSM_80.tif\n",
      "Missing SAR for 441_OSM_80.tif\n",
      "Missing SAR for 35_OSM_80.tif\n",
      "Missing SAR for 414_OSM_80.tif\n",
      "Missing SAR for 423_OSM_80.tif\n",
      "Missing SAR for 549_OSM_80.tif\n",
      "Missing SAR for 120_OSM_80.tif\n",
      "Missing SAR for 675_OSM_80.tif\n",
      "Missing SAR for 419_OSM_80.tif\n",
      "Missing SAR for 664_OSM_80.tif\n",
      "Missing SAR for 21_Aus_80.tif\n",
      "Missing SAR for 653_OSM_80.tif\n",
      "Missing SAR for 131_OSM_80.tif\n",
      "Missing SAR for 558_OSM_80.tif\n",
      "Missing SAR for 432_OSM_80.tif\n",
      "Missing SAR for 24_OSM_80.tif\n",
      "Missing SAR for 450_OSM_80.tif\n",
      "Missing SAR for 544_OSM_80.tif\n",
      "Missing SAR for 211_OSM_80.tif\n",
      "Missing SAR for 435_OSM_80.tif\n",
      "Missing SAR for 23_OSM_80.tif\n",
      "Missing SAR for 543_OSM_80.tif\n",
      "Missing SAR for 429_OSM_80.tif\n",
      "Missing SAR for 654_OSM_80.tif\n",
      "Missing SAR for 127_OSM_80.tif\n",
      "Missing SAR for 438_OSM_80.tif\n",
      "Missing SAR for 446_OSM_80.tif\n",
      "Missing SAR for 207_OSM_80.tif\n",
      "Missing SAR for 565_OSM_80.tif\n",
      "Missing SAR for 552_OSM_80.tif\n",
      "Missing SAR for 413_OSM_80.tif\n",
      "Missing SAR for 424_OSM_80.tif\n",
      "Missing SAR for 659_OSM_80.tif\n",
      "Missing SAR for 677_OSM_80.tif\n",
      "Missing SAR for 557_OSM_80.tif\n",
      "Missing SAR for 560_OSM_80.tif\n",
      "Missing SAR for 443_OSM_80.tif\n",
      "Missing SAR for 421_OSM_80.tif\n",
      "Missing SAR for 416_OSM_80.tif\n",
      "Missing SAR for 194_OSM_80.tif\n",
      "Missing SAR for 26_OSM_80.tif\n",
      "Missing SAR for 430_OSM_80.tif\n",
      "Missing SAR for 452_OSM_80.tif\n",
      "Missing SAR for 546_OSM_80.tif\n",
      "Missing SAR for 651_OSM_80.tif\n",
      "Missing SAR for 23_Aus_80.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "remove_list = []\n",
    "for image in tqdm(images):\n",
    "    expected_label = labels_path / image.name\n",
    "    expected_sar = sar_path / image.name\n",
    "    if not expected_label.exists():\n",
    "        print(f\"Missing label for {image.name}\")\n",
    "        remove_list.append(image)\n",
    "    if not expected_sar.exists():\n",
    "        print(f\"Missing SAR for {image.name}\")\n",
    "        # remove_list.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in remove_list:\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
