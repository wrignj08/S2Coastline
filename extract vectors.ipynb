{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import numpy as np\n",
    "from rasterio import features\n",
    "import rasterio as rio\n",
    "from tqdm.auto import tqdm\n",
    "from shapely.geometry import shape, box\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "if sys.platform == \"darwin\":\n",
    "    from multiprocess import Pool\n",
    "else:\n",
    "    from multiprocessing import Pool\n",
    "\n",
    "\n",
    "from shapely.geometry import box\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_coverage_path = Path(\"data/S-2 coverage area.gpkg\")\n",
    "s2_coverage_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"regnety_002_v1.29_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path the the inference rasters\n",
    "input_rasters = Path(\"/Users/nick/Desktop/CL test/Aus working v8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters = list(input_rasters.glob(\"*pred.tif\"))\n",
    "len(rasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the output path\n",
    "output_vector = input_rasters.parent / f\"{input_rasters.name}_{model_name}.gpkg\"\n",
    "output_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the geometries to make them less blocky\n",
    "def simplify_geometries(gdf: gpd.GeoDataFrame, tolerance: float) -> gpd.GeoDataFrame:\n",
    "    new_gdf = gdf.copy()\n",
    "    new_gdf[\"geometry\"] = new_gdf[\"geometry\"].simplify(\n",
    "        tolerance, preserve_topology=False\n",
    "    )\n",
    "    return gpd.GeoDataFrame(new_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raster_bounds(raster):\n",
    "    with rio.open(raster) as src:\n",
    "        bounds = box(*src.bounds)\n",
    "        bounds_gdf = gpd.GeoDataFrame({\"geometry\": [bounds]})\n",
    "        bounds_gdf.set_crs(src.crs, inplace=True)\n",
    "        bounds_gdf = bounds_gdf.to_crs(3857)\n",
    "        if bounds_gdf is not None:\n",
    "            extent = bounds_gdf.geometry.values[0]\n",
    "            return extent\n",
    "        raise ValueError(\"No bounds found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_bounds = []\n",
    "for raster in tqdm(rasters):\n",
    "    raster_bounds.append(get_raster_bounds(raster))\n",
    "bounds_gdf = gpd.GeoDataFrame(geometry=raster_bounds)\n",
    "bounds_gdf.set_crs(\"EPSG:3857\", inplace=True)\n",
    "bounds_gdf = bounds_gdf.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the polygons from the rasters and reproject them to 3857\n",
    "def extract_polygons(chunk, px_size):\n",
    "    with rio.open(chunk) as src:\n",
    "        local_epsg = src.meta[\"crs\"].to_epsg()\n",
    "        water_array = src.read(1).astype(\"uint8\")\n",
    "        mask = water_array == 1\n",
    "    bounds = box(*src.bounds)\n",
    "\n",
    "    shapes = features.shapes(\n",
    "        water_array, mask=mask, transform=src.transform, connectivity=4\n",
    "    )\n",
    "    water_array = None\n",
    "    geoms = []\n",
    "    values = []\n",
    "    for shape_dict, value in shapes:\n",
    "        geoms.append(shape(shape_dict))\n",
    "        values.append(value)\n",
    "\n",
    "    water_gdf = gpd.GeoDataFrame({\"geometry\": geoms}, crs=f\"EPSG:{local_epsg}\")\n",
    "    water_gdf = simplify_geometries(water_gdf, px_size)\n",
    "\n",
    "    # clip edge 3km buffer\n",
    "\n",
    "    water_gdf_wgs = water_gdf.to_crs(3857)\n",
    "\n",
    "    water_gdf_wgs[\"geometry\"] = water_gdf_wgs.buffer(0)\n",
    "\n",
    "    return water_gdf_wgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_polygons_partial = partial(extract_polygons, px_size=10)\n",
    "with Pool() as p:\n",
    "    water_polygons = list(\n",
    "        tqdm(p.imap(extract_polygons_partial, rasters), total=len(rasters))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all chunks into one gdf and dissolve\n",
    "joined_water_gdf = pd.concat(water_polygons, ignore_index=True)\n",
    "joined_water_gdf_dis = joined_water_gdf.dissolve()\n",
    "joined_water_gdf_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_water_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert multipart poly to single part so we can sort by size to remove lakes and rivers\n",
    "single_part_gdf = joined_water_gdf_dis.explode(index_parts=False)\n",
    "single_part_gdf[\"area\"] = single_part_gdf.area\n",
    "# only keep the largest area polygon\n",
    "single_part_gdf = single_part_gdf.sort_values(\"area\", ascending=False)\n",
    "single_part_gdf = single_part_gdf.iloc[[0]]\n",
    "single_part_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lines to get the coastline\n",
    "single_part_gdf.geometry = single_part_gdf.boundary\n",
    "single_part_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_part_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip coastline to the bounds of the rasters to remove the edge lines\n",
    "old_crs = bounds_gdf.crs.to_epsg()\n",
    "bounds_gdf.to_crs(3857, inplace=True)\n",
    "bounds_gdf.geometry = bounds_gdf.buffer(-10)\n",
    "bounds_gdf.to_crs(old_crs, inplace=True)\n",
    "\n",
    "\n",
    "clipped_gdf = gpd.clip(single_part_gdf, bounds_gdf).explode(index_parts=False)\n",
    "clipped_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_part_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = gpd.read_file(s2_coverage_path)\n",
    "# buffer by 1\n",
    "coverage.geometry = coverage.buffer(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = gpd.read_file(s2_coverage_path)\n",
    "coverage.geometry = coverage.buffer(-0.5)\n",
    "coverage.to_crs(4326, inplace=True)\n",
    "\n",
    "old_crs = clipped_gdf.crs.to_epsg()\n",
    "clipped_gdf.to_crs(4326, inplace=True)\n",
    "\n",
    "\n",
    "clipped_gdf = gpd.sjoin(clipped_gdf, coverage, how=\"inner\", op=\"intersects\")\n",
    "\n",
    "clipped_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chaikin_corner_cutting_optimized(\n",
    "    points: np.ndarray, num_iterations: int = 1\n",
    ") -> np.ndarray:\n",
    "    for _ in range(num_iterations):\n",
    "        if np.array_equal(points[0], points[-1]):\n",
    "            points = np.append(points, [points[1]], axis=0)\n",
    "\n",
    "        p0 = points[:-1]\n",
    "        p1 = points[1:]\n",
    "        q = p0 * 0.75 + p1 * 0.25\n",
    "        r = p0 * 0.25 + p1 * 0.75\n",
    "        new_points = np.empty((2 * len(points) - 2, points.shape[1]))\n",
    "        new_points[0::2] = q\n",
    "        new_points[1::2] = r\n",
    "\n",
    "        if np.array_equal(points[0], points[-2]):\n",
    "            new_points = new_points[1:]\n",
    "            new_points = np.append(new_points, [new_points[0]], axis=0)\n",
    "        else:\n",
    "            new_points = np.append(new_points, [points[-1]], axis=0)\n",
    "\n",
    "        points = new_points\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def smooth_geodataframe_optimized(\n",
    "    gdf: gpd.GeoDataFrame, num_iterations: int = 1\n",
    ") -> gpd.GeoDataFrame:\n",
    "    gdf[\"geometry\"] = gdf[\"geometry\"].apply(\n",
    "        lambda line: LineString(\n",
    "            chaikin_corner_cutting_optimized(\n",
    "                np.array(line.coords), num_iterations=num_iterations\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth all the lines\n",
    "lines_gpd = smooth_geodataframe_optimized(clipped_gdf, num_iterations=2)\n",
    "lines_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_gpd.to_file(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
