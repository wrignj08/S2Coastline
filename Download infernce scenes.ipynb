{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook downloads data from PC in the format required by the inference notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/rs7d6smx5kv8n5mp22x8kgjr0000gq/T/ipykernel_74167/1172969497.py:6: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import planetary_computer\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from tqdm.auto import tqdm\n",
    "from shapely.geometry import Polygon, shape\n",
    "from shapely.ops import transform\n",
    "from rasterio.merge import merge\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the world tide api key, let me know if you need it\n",
    "world_tide_key_file = Path.cwd() / \"world_tide_key.txt\"\n",
    "world_tides_api_key = world_tide_key_file.read_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Volumes/4TB SSD/Coastline data/inference_scenes_5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is output dir, each scene will end up about 2Gb so make sure you have space!\n",
    "export_dir = Path(\"/Volumes/4TB SSD/Coastline data\") / \"inference_scenes_5\"\n",
    "export_dir.mkdir(exist_ok=True, parents=True)\n",
    "export_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_bands = [\"B03\", \"B08\"]\n",
    "target_bands = 12\n",
    "time_steps = 6\n",
    "extract_start_year = 2022\n",
    "extract_end_year = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the sentinel 2 grid, limited to just Tas at the moment\n",
    "sentinel_2_grid = Path.cwd() / \"data/Senntinele 2 grid coastal tas.gpkg\"\n",
    "s2_grid = gpd.read_file(sentinel_2_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cloud_pct(items_df):\n",
    "    items_df[\"cloud_pct\"] = items_df.apply(\n",
    "        lambda row: row[0].properties[\"eo:cloud_cover\"], axis=1\n",
    "    )\n",
    "    return items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_cloud_pct(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the world tide api to get the tide height at the time of the image\n",
    "def add_tide_height(centroid, items_df):\n",
    "    results = []\n",
    "    lon, lat = centroid.coords[0]\n",
    "    for id, item in items_df.iterrows():\n",
    "        dt_str = item[0].to_dict()[\"properties\"][\"datetime\"]\n",
    "\n",
    "        dt_obj = datetime.fromisoformat(dt_str.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "        # Fetch data from API\n",
    "        url = f\"https://www.worldtides.info/api/v3?heights&date={dt_obj.date().isoformat()}&lat={lat}&lon={lon}&key={world_tides_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        data = json.loads(response.text)\n",
    "\n",
    "        min_diff = float(\"inf\")\n",
    "\n",
    "        target_timestamp = dt_obj.timestamp()\n",
    "        for entry in data[\"heights\"]:\n",
    "            diff = abs(entry[\"dt\"] - target_timestamp)\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                closest_entry = entry\n",
    "\n",
    "        results.append(closest_entry[\"height\"])\n",
    "    # convert to df and sort by tide height\n",
    "    # results_df = pd.DataFrame(results).sort_values(by=\"tide\", ascending=False)[:limit]\n",
    "    items_df[\"tide_height\"] = results\n",
    "\n",
    "    return items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign the url and download the band\n",
    "def get_band(href, attempt=0):\n",
    "    try:\n",
    "        singed_href = planetary_computer.sign(href)\n",
    "        with rio.open(singed_href) as src:\n",
    "            return src.read(1), src.profile.copy()\n",
    "    except:\n",
    "        print(f\"Failed to open {href}\")\n",
    "        if attempt < 3:\n",
    "            print(f\"Trying again {attempt+1}\")\n",
    "            return get_band(href, attempt + 1)\n",
    "        else:\n",
    "            print(f\"Failed to open {href} after 3 attempts\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downlaod the required number of bands\n",
    "def downlaod_bands(items_with_tide, time_steps):\n",
    "    bands = []\n",
    "    profile = {}\n",
    "    pbar = tqdm(total=time_steps * len(required_bands), leave=False)\n",
    "    for id, row in items_with_tide.iterrows():\n",
    "        scene_bands = []\n",
    "\n",
    "        for band in required_bands:\n",
    "            href = row[\"item\"].assets[band].href\n",
    "            band, profile = get_band(href)\n",
    "            if type(band) == type(None):\n",
    "                print(f\"Failed to download {href}\")\n",
    "                scene_bands = []\n",
    "                break\n",
    "            pbar.update(1)\n",
    "\n",
    "            scene_bands.append(band)\n",
    "        for band in scene_bands:\n",
    "            bands.append(band)\n",
    "        if len(bands) == time_steps * len(required_bands):\n",
    "            return bands, profile\n",
    "    return bands, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each grid location may have multiple orbits which covers it, list each orbit\n",
    "def split_by_orbits(items):\n",
    "    orbits = {}\n",
    "    for item in items:\n",
    "        orbit = item.properties[\"sat:relative_orbit\"]\n",
    "        if orbit not in orbits:\n",
    "            orbits[orbit] = [item]\n",
    "        else:\n",
    "            orbits[orbit].append(item)\n",
    "    return orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tif(bands, profile, export_path):\n",
    "    array = np.array(bands)\n",
    "    profile.update(count=array.shape[0])\n",
    "    with rio.open(export_path, \"w\", **profile) as dst:\n",
    "        dst.write(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_grid = s2_grid.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55HES</td>\n",
       "      <td>MULTIPOLYGON Z (((146.99977 -38.84846 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55GEQ</td>\n",
       "      <td>MULTIPOLYGON Z (((146.99976 -40.65086 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55GCN</td>\n",
       "      <td>MULTIPOLYGON Z (((144.56882 -42.42636 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55GCR</td>\n",
       "      <td>MULTIPOLYGON Z (((144.66639 -39.72627 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55GCQ</td>\n",
       "      <td>MULTIPOLYGON Z (((144.63532 -40.62664 0.00000,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name                                           geometry\n",
       "23  55HES  MULTIPOLYGON Z (((146.99977 -38.84846 0.00000,...\n",
       "15  55GEQ  MULTIPOLYGON Z (((146.99976 -40.65086 0.00000,...\n",
       "5   55GCN  MULTIPOLYGON Z (((144.56882 -42.42636 0.00000,...\n",
       "8   55GCR  MULTIPOLYGON Z (((144.66639 -39.72627 0.00000,...\n",
       "7   55GCQ  MULTIPOLYGON Z (((144.63532 -40.62664 0.00000,..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id, row in s2_grid.iterrows():\n",
    "def download_scene(row):\n",
    "    _, row = row\n",
    "    centroid = row.geometry.centroid\n",
    "    export_path = export_dir / f\"{row.Name}_{extract_start_year}_{extract_end_year}.tif\"\n",
    "    print(export_path)\n",
    "\n",
    "    if export_path.exists():\n",
    "        print(f\"File exists for {row.Name}\")\n",
    "        return\n",
    "\n",
    "    # Sentinel-2 query parameters\n",
    "    query = {\n",
    "        \"collections\": [\"sentinel-2-l2a\"],\n",
    "        \"intersects\": shapely.to_geojson(centroid),\n",
    "        \"datetime\": f\"{extract_start_year}-01-01T00:00:00Z/{extract_end_year}-12-31T23:59:59Z\",\n",
    "        \"query\": {\"s2:mgrs_tile\": {\"eq\": row.Name}},\n",
    "    }\n",
    "    scenes = catalog.search(**query).get_all_items()\n",
    "    # break\n",
    "    if len(scenes) == 0:\n",
    "        return\n",
    "\n",
    "    scenes_by_orbit = split_by_orbits(scenes)\n",
    "    all_orbits_bands = []\n",
    "    for orbit, scenes in scenes_by_orbit.items():\n",
    "        # make df from items in orbit\n",
    "        items_df = pd.DataFrame(scenes)\n",
    "        items_df.columns = [\"item\"]\n",
    "\n",
    "        items_df = add_cloud_pct(items_df)\n",
    "        # sort by cloud cover\n",
    "        items_df = items_df.sort_values(by=\"cloud_pct\", ascending=True)\n",
    "        # only keep the top 20 scenes\n",
    "        items_df = items_df[:20]\n",
    "        items_df = add_tide_height(centroid, items_df)\n",
    "        # round tide height to nearest 10\n",
    "        items_df[\"cloud_pct\"] = items_df[\"cloud_pct\"].apply(\n",
    "            lambda x: round(x / 10) * 10\n",
    "        )\n",
    "        # Sort by cloud_pct and then by tide_height\n",
    "        items_df = items_df.sort_values(\n",
    "            by=[\"cloud_pct\", \"tide_height\"], ascending=[True, False]\n",
    "        )\n",
    "        # download the required bands\n",
    "        bands, profile = downlaod_bands(items_df, time_steps)\n",
    "        all_orbits_bands.append(bands)\n",
    "\n",
    "    all_orbits_bands = np.array(all_orbits_bands)\n",
    "    all_orbits_bands = np.moveaxis(all_orbits_bands, 0, 1)\n",
    "\n",
    "    merged_bands = []\n",
    "    for multi_orbit_bands in all_orbits_bands:\n",
    "        target_array = np.zeros(multi_orbit_bands.shape[1:])\n",
    "        for band in multi_orbit_bands:\n",
    "            target_array[target_array == 0] = band[target_array == 0]\n",
    "        merged_bands.append(target_array)\n",
    "    # merged_bands = np.array(merged_bands)\n",
    "\n",
    "    if len(merged_bands) == target_bands:\n",
    "        export_tif(merged_bands, profile, export_path)\n",
    "    else:\n",
    "        print(f\"Failed to download {row.Name}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55HES_2022_2022.tif/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GEQ_2022_2022.tif\n",
      "\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GCR_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GCN_2022_2022.tif\n",
      "File exists for 55GCR\n",
      "File exists for 55GEQ\n",
      "File exists for 55HES\n",
      "File exists for 55GCN\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GFQ_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GFR_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55HCS_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GCQ_2022_2022.tif\n",
      "File exists for 55GFR\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GER_2022_2022.tif\n",
      "File exists for 55HCS\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/54GYA_2022_2022.tif\n",
      "File exists for 54GYA\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GEM_2022_2022.tif\n",
      "File exists for 55GFQ\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GEP_2022_2022.tif\n",
      "File exists for 55GEM\n",
      "File exists for 55GCQ\n",
      "File exists for 55GER\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GBQ_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GDQ_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55HDS_2022_2022.tif\n",
      "File exists for 55GEP\n",
      "File exists for 55GBQ\n",
      "File exists for 55GDQ\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GCP_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/54HYB_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55HBS_2022_2022.tif\n",
      "File exists for 55HDS\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GDM_2022_2022.tif\n",
      "File exists for 54HYB\n",
      "File exists for 55HBS\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GFP_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GDN_2022_2022.tif\n",
      "File exists for 55GDM\n",
      "File exists for 55GFP\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GBR_2022_2022.tif\n",
      "File exists for 55GDN\n",
      "File exists for 55GBR\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/54GYV_2022_2022.tif\n",
      "/Volumes/4TB SSD/Coastline data/inference_scenes_5/55GEN_2022_2022.tif\n",
      "File exists for 54GYV\n",
      "File exists for 55GEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/gis_311/lib/python3.11/site-packages/pystac_client/item_search.py:841: FutureWarning: get_all_items() is deprecated, use item_collection() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fa4e1038894c5e89a12497477e988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# call download_scene with a thread pool\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as pool:\n",
    "    pool.map(download_scene, s2_grid.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
