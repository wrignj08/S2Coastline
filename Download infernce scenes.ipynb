{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook downloads data from PC in the format required by the inference notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/rs7d6smx5kv8n5mp22x8kgjr0000gq/T/ipykernel_42888/3607905791.py:6: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import planetary_computer\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from shapely.geometry import Polygon, shape\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from rasterio.merge import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the world tide api key, let me know if you need it\n",
    "planetary_computer_key_file = Path.cwd() / \"planitary_computer_key.txt\"\n",
    "planetary_computer_api_key = planetary_computer_key_file.read_text().strip()\n",
    "os.environ[\"PC_SDK_SUBSCRIPTION_KEY\"] = planetary_computer_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the world tide api key, let me know if you need it\n",
    "world_tide_key_file = Path.cwd() / \"world_tide_key.txt\"\n",
    "world_tides_api_key = world_tide_key_file.read_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Volumes/4TB SSD/Coastline data/inference_scenes_3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is output dir, each scene will end up about 2Gb so make sure you have space!\n",
    "export_dir = Path(\"/Volumes/4TB SSD/Coastline data\") / \"inference_scenes_3\"\n",
    "export_dir.mkdir(exist_ok=True, parents=True)\n",
    "export_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_bands = [\"B03\", \"B08\"]\n",
    "extract_start_year = 2022\n",
    "extract_end_year = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the sentinel 2 grid, limited to just Tas at the moment\n",
    "sentinel_2_grid = Path.cwd() / \"data/Senntinele 2 grid coastal tas.gpkg\"\n",
    "s2_grid = gpd.read_file(sentinel_2_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the scenes by cloud cover\n",
    "def sort_by_clouds(row, items):\n",
    "    filtered_items = [\n",
    "        item\n",
    "        for item in items\n",
    "        if eo.ext(item).cloud_cover is not None and row.Name in item.id\n",
    "    ]\n",
    "    sorted_items = sorted(filtered_items, key=lambda x: eo.ext(x).cloud_cover)\n",
    "    return sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the world tide api to get the tide height at the time of the image\n",
    "def filter_by_tide(centroid, items, limit=6):\n",
    "    results = []\n",
    "    for item in items:\n",
    "        lon, lat = centroid.coords[0]\n",
    "\n",
    "        dt_str = item.to_dict()[\"properties\"][\"datetime\"]\n",
    "\n",
    "        dt_obj = datetime.fromisoformat(dt_str.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "        # Fetch data from API\n",
    "        url = f\"https://www.worldtides.info/api/v3?heights&date={dt_obj.date().isoformat()}&lat={lat}&lon={lon}&key={world_tides_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        data = json.loads(response.text)\n",
    "\n",
    "        if data == {\"status\": 400, \"error\": \"No location found\"}:\n",
    "            print(\"No location found in world tides\")\n",
    "            return pd.DataFrame({\"items\": items, \"tide\": np.full(len(items), np.nan)})[\n",
    "                :limit\n",
    "            ]\n",
    "\n",
    "        min_diff = float(\"inf\")\n",
    "\n",
    "        target_timestamp = dt_obj.timestamp()\n",
    "        for entry in data[\"heights\"]:\n",
    "            diff = abs(entry[\"dt\"] - target_timestamp)\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                closest_entry = entry\n",
    "\n",
    "        results.append({\"item\": item, \"tide\": closest_entry[\"height\"]})\n",
    "    # convert to df and sort by tide height\n",
    "    results_df = pd.DataFrame(results).sort_values(by=\"tide\", ascending=False)[:limit]\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign the url and download the band\n",
    "def get_band(href, attempt=0):\n",
    "    try:\n",
    "        singed_href = planetary_computer.sign(href)\n",
    "        with rio.open(singed_href) as src:\n",
    "            return src.read(1), src.profile.copy()\n",
    "    except:\n",
    "        print(f\"Failed to open {href}\")\n",
    "        if attempt < 3:\n",
    "            print(f\"Trying again {attempt+1}\")\n",
    "            return get_band(href, attempt + 1)\n",
    "        else:\n",
    "            print(f\"Failed to open {href} after 3 attempts\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downlaod the required number of bands\n",
    "def downlaod_bands(items_with_tide, time_steps):\n",
    "    bands = []\n",
    "    profile = {}\n",
    "    pbar = tqdm(total=time_steps * len(required_bands), leave=False)\n",
    "    for id, row in items_with_tide.iterrows():\n",
    "        scene_bands = []\n",
    "\n",
    "        for band in required_bands:\n",
    "            href = row[\"item\"].assets[band].href\n",
    "            band, profile = get_band(href)\n",
    "            if type(band) == type(None):\n",
    "                print(f\"Failed to download {href}\")\n",
    "                scene_bands = []\n",
    "                break\n",
    "            pbar.update(1)\n",
    "\n",
    "            scene_bands.append(band)\n",
    "        for band in scene_bands:\n",
    "            bands.append(band)\n",
    "        if len(bands) == time_steps * len(required_bands):\n",
    "            return bands, profile\n",
    "    return bands, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each grid location may have multiple orbits which covers it, list each orbit\n",
    "def split_by_orbits(items):\n",
    "    orbits = {}\n",
    "    for item in items:\n",
    "        orbit = item.properties[\"sat:relative_orbit\"]\n",
    "        if orbit not in orbits:\n",
    "            orbits[orbit] = [item]\n",
    "        else:\n",
    "            orbits[orbit].append(item)\n",
    "    return orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tif(bands, profile, export_path):\n",
    "    array = np.array(bands)\n",
    "    profile.update(count=array.shape[0])\n",
    "    with rio.open(export_path, \"w\", **profile) as dst:\n",
    "        dst.write(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_grid = s2_grid.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>55GFR</td>\n",
       "      <td>MULTIPOLYGON Z (((148.16715 -39.74386 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54HYB</td>\n",
       "      <td>MULTIPOLYGON Z (((143.30345 -38.82574 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55HDS</td>\n",
       "      <td>MULTIPOLYGON Z (((145.84726 -38.84277 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55GDQ</td>\n",
       "      <td>MULTIPOLYGON Z (((145.81683 -40.64479 0.00000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55GBR</td>\n",
       "      <td>MULTIPOLYGON Z (((143.50105 -39.69697 0.00000,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name                                           geometry\n",
       "19  55GFR  MULTIPOLYGON Z (((148.16715 -39.74386 0.00000,...\n",
       "2   54HYB  MULTIPOLYGON Z (((143.30345 -38.82574 0.00000,...\n",
       "22  55HDS  MULTIPOLYGON Z (((145.84726 -38.84277 0.00000,...\n",
       "11  55GDQ  MULTIPOLYGON Z (((145.81683 -40.64479 0.00000,...\n",
       "4   55GBR  MULTIPOLYGON Z (((143.50105 -39.69697 0.00000,..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bands = 12\n",
    "time_steps = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, row in s2_grid.iterrows():\n",
    "    centroid = row.geometry.centroid\n",
    "    export_path = export_dir / f\"{row.Name}_{extract_start_year}_{extract_end_year}.tif\"\n",
    "    print(export_path)\n",
    "\n",
    "    if export_path.exists():\n",
    "        print(f\"File exists for {row.Name}\")\n",
    "        continue\n",
    "\n",
    "    # Sentinel-2 query parameters\n",
    "    query = {\n",
    "        \"collections\": [\"sentinel-2-l2a\"],\n",
    "        \"intersects\": shapely.to_geojson(centroid),\n",
    "        \"datetime\": f\"{extract_start_year}-01-01T00:00:00Z/{extract_end_year}-12-31T23:59:59Z\",\n",
    "    }\n",
    "    scenes = catalog.search(**query).get_all_items()\n",
    "    # break\n",
    "    if len(scenes) == 0:\n",
    "        continue\n",
    "\n",
    "    scenes_by_orbit = split_by_orbits(scenes)\n",
    "    all_orbits_bands = []\n",
    "    for orbit, scenes in scenes_by_orbit.items():\n",
    "        items_filtered = sort_by_clouds(row, scenes)\n",
    "        items_filtered = items_filtered[:20]\n",
    "        # break\n",
    "        items_with_tide = filter_by_tide(centroid, items_filtered, limit=8)\n",
    "        bands, profile = downlaod_bands(items_with_tide, time_steps)\n",
    "        all_orbits_bands.append(bands)\n",
    "        # break\n",
    "    # break\n",
    "\n",
    "    all_orbits_bands = np.array(all_orbits_bands)\n",
    "    all_orbits_bands = np.moveaxis(all_orbits_bands, 0, 1)\n",
    "\n",
    "    merged_bands = []\n",
    "    for multi_orbit_bands in all_orbits_bands:\n",
    "        target_array = np.zeros(multi_orbit_bands.shape[1:])\n",
    "        for band in multi_orbit_bands:\n",
    "            target_array[target_array == 0] = band[target_array == 0]\n",
    "        merged_bands.append(target_array)\n",
    "    # merged_bands = np.array(merged_bands)\n",
    "\n",
    "    if len(merged_bands) == target_bands:\n",
    "        export_tif(merged_bands, profile, export_path)\n",
    "    else:\n",
    "        print(f\"Failed to download {row.Name}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes = list(export_dir.glob(\"*.tif\"))\n",
    "len(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenes = [Path(\"/Volumes/4TB SSD/Coastline data/small test.tif\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49038440\n",
      "35657766\n",
      "855\n",
      "851\n",
      "0\n",
      "56829186\n",
      "60649\n",
      "3763\n",
      "3763\n",
      "3654\n",
      "3654\n",
      "3654\n",
      "3654\n",
      "3654\n"
     ]
    }
   ],
   "source": [
    "for scene in scenes:\n",
    "    stack_src = rio.open(scene)\n",
    "    local_bounds = shapely.geometry.box(*stack_src.bounds)\n",
    "\n",
    "    original_crs = stack_src.profile[\"crs\"]\n",
    "    target_crs = pyproj.CRS(\"EPSG:4326\")\n",
    "    # Create a pyproj transformer\n",
    "    project = pyproj.Transformer.from_crs(\n",
    "        original_crs, target_crs, always_xy=True\n",
    "    ).transform\n",
    "\n",
    "    # Transform the polygon\n",
    "    wgs_bounds = transform(project, local_bounds)\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"],\n",
    "        intersects=wgs_bounds,\n",
    "    )\n",
    "    items = search.item_collection()\n",
    "    srcs = []\n",
    "    nodata_count = True\n",
    "    merge_list = []\n",
    "    parts = []\n",
    "    part_number = 0\n",
    "    for item in items:\n",
    "        href = item.assets[\"vh\"].href\n",
    "        src = rio.open(planetary_computer.sign(href))\n",
    "        if src.crs != original_crs:\n",
    "            continue\n",
    "\n",
    "        window = rio.windows.from_bounds(*stack_src.bounds, src.transform)\n",
    "        array = src.read(1, window=window)\n",
    "        transfm = rio.windows.transform(window, transform=src.transform)\n",
    "        profile = src.profile.copy()\n",
    "\n",
    "        profile.update(\n",
    "            width=array.shape[-1],\n",
    "            height=array.shape[-2],\n",
    "            transform=transfm,\n",
    "            count=1,\n",
    "            dtype=\"float32\",\n",
    "        )\n",
    "        sar_path = Path(str(scene).replace(\".tif\", f\"_{part_number}_sar.tif\"))\n",
    "        part_number += 1\n",
    "        parts.append(sar_path)\n",
    "        with rio.open(sar_path, \"w\", **profile) as dst:\n",
    "            dst.write(array, 1)\n",
    "\n",
    "        for i in parts:\n",
    "            merge_list.append(rio.open(sar_path))\n",
    "\n",
    "        mosaic, out_trans = merge(merge_list)\n",
    "        # count zeros in array\n",
    "        nodata_count = np.count_nonzero(mosaic == -32768)\n",
    "        print(nodata_count)\n",
    "        if nodata_count == 0:\n",
    "            break\n",
    "    sar_path = Path(str(scene).replace(\".tif\", f\"_sar.tif\"))\n",
    "\n",
    "    profile.update(\n",
    "        width=mosaic.shape[-1],\n",
    "        height=mosaic.shape[-2],\n",
    "        transform=out_trans,\n",
    "        count=1,\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "    with rio.open(sar_path, \"w\", **profile) as dst:\n",
    "        dst.write(mosaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Volumes/4TB SSD/Coastline data/small test_0_sar.tif')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -32768.0, 'width': 1163.0, 'height': 1140.0, 'count': 1, 'crs': CRS.from_epsg(32755), 'transform': Affine(10.0, 0.0, 524080.0,\n",
       "       0.0, -10.0, 5470450.0), 'blockxsize': 512, 'blockysize': 512, 'tiled': True, 'compress': 'deflate', 'interleave': 'band'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile.update(count=1, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_bounds.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planetary_computer.sign(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = stack_src.profile.copy()\n",
    "profile[\"count\"] = 1\n",
    "profile[\"dtype\"] = \"float32\"\n",
    "\n",
    "with rio.open(\"test.tif\", \"w\", **profile) as dst:\n",
    "    dst.write(array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
