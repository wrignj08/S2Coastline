{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import planetary_computer\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_tide_key_file = Path.cwd() / \"world_tide_key.txt\"\n",
    "world_tides_api_key = world_tide_key_file.read_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Volumes/4TB SSD/Coastline data/inference_scenes_2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_dir = Path(\"/Volumes/4TB SSD/Coastline data\") / \"inference_scenes_2\"\n",
    "export_dir.mkdir(exist_ok=True, parents=True)\n",
    "export_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_bands = [\"B03\", \"B08\"]\n",
    "extract_start_year = 2022\n",
    "extract_end_year = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_2_grid = Path.cwd() / \"data/Senntinele 2 grid coastal tas.gpkg\"\n",
    "\n",
    "s2_grid = gpd.read_file(sentinel_2_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_clouds(row, items):\n",
    "    filtered_items = [\n",
    "        item\n",
    "        for item in items\n",
    "        if eo.ext(item).cloud_cover is not None and row.Name in item.id\n",
    "    ]\n",
    "    sorted_items = sorted(filtered_items, key=lambda x: eo.ext(x).cloud_cover)\n",
    "    return sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_tide(centroid, items, limit=6):\n",
    "    results = []\n",
    "    for item in items:\n",
    "        # Initialize parameters\n",
    "        lon, lat = centroid.coords[0]\n",
    "\n",
    "        dt_str = item.to_dict()[\"properties\"][\"datetime\"]\n",
    "\n",
    "        # Loop through each date-time string\n",
    "        dt_obj = datetime.fromisoformat(dt_str.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "        # Fetch data from API\n",
    "        url = f\"https://www.worldtides.info/api/v3?heights&date={dt_obj.date().isoformat()}&lat={lat}&lon={lon}&key={world_tides_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        data = json.loads(response.text)\n",
    "        if data == {\"status\": 400, \"error\": \"No location found\"}:\n",
    "            print(\"No location found in world tides\")\n",
    "            return pd.DataFrame({\"items\": items, \"tide\": np.full(len(items), np.nan)})[\n",
    "                :limit\n",
    "            ]\n",
    "\n",
    "        min_diff = float(\"inf\")\n",
    "\n",
    "        target_timestamp = dt_obj.timestamp()\n",
    "        for entry in data[\"heights\"]:\n",
    "            diff = abs(entry[\"dt\"] - target_timestamp)\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                closest_entry = entry\n",
    "\n",
    "        results.append({\"item\": item, \"tide\": closest_entry[\"height\"]})\n",
    "    # convert to df and sort by tide height\n",
    "    results_df = pd.DataFrame(results).sort_values(by=\"tide\", ascending=False)[:limit]\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_band(href, attempt=0):\n",
    "    try:\n",
    "        singed_href = planetary_computer.sign(href)\n",
    "        with rio.open(singed_href) as src:\n",
    "            return src.read(1), src.profile.copy()\n",
    "    except:\n",
    "        print(f\"Failed to open {href}\")\n",
    "        if attempt < 3:\n",
    "            print(f\"Trying again {attempt+1}\")\n",
    "            return get_band(href, attempt + 1)\n",
    "        else:\n",
    "            print(f\"Failed to open {href} after 3 attempts\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downlaod_bands(items_with_tide, time_steps):\n",
    "    bands = []\n",
    "    profile = {}\n",
    "    pbar = tqdm(total=time_steps * len(required_bands), leave=False)\n",
    "    for id, row in items_with_tide.iterrows():\n",
    "        scene_bands = []\n",
    "\n",
    "        for band in required_bands:\n",
    "            href = row[\"item\"].assets[band].href\n",
    "            band, profile = get_band(href)\n",
    "            if type(band) == type(None):\n",
    "                print(f\"Failed to download {href}\")\n",
    "                scene_bands = []\n",
    "                break\n",
    "            pbar.update(1)\n",
    "\n",
    "            scene_bands.append(band)\n",
    "        for band in scene_bands:\n",
    "            bands.append(band)\n",
    "        if len(bands) == time_steps * len(required_bands):\n",
    "            return bands, profile\n",
    "    return bands, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_orbits(items):\n",
    "    orbits = {}\n",
    "    for item in items:\n",
    "        orbit = item.properties[\"sat:relative_orbit\"]\n",
    "        if orbit not in orbits:\n",
    "            orbits[orbit] = [item]\n",
    "        else:\n",
    "            orbits[orbit].append(item)\n",
    "    return orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tif(bands, profile, export_path):\n",
    "    array = np.array(bands)\n",
    "    profile.update(count=array.shape[0])\n",
    "    with rio.open(export_path, \"w\", **profile) as dst:\n",
    "        dst.write(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_grid = s2_grid.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bands = 12\n",
    "time_steps = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, row in s2_grid.iterrows():\n",
    "    centroid = row.geometry.centroid\n",
    "    export_path = export_dir / f\"{row.Name}_{extract_start_year}_{extract_end_year}.tif\"\n",
    "    print(export_path)\n",
    "\n",
    "    if export_path.exists():\n",
    "        print(f\"File exists for {row.Name}\")\n",
    "        continue\n",
    "\n",
    "    # Sentinel-2 query parameters\n",
    "    query = {\n",
    "        \"collections\": [\"sentinel-2-l2a\"],\n",
    "        \"intersects\": shapely.to_geojson(centroid),\n",
    "        \"datetime\": f\"{extract_start_year}-01-01T00:00:00Z/{extract_end_year}-12-31T23:59:59Z\",\n",
    "    }\n",
    "    scenes = catalog.search(**query).get_all_items()\n",
    "    # break\n",
    "    if len(scenes) == 0:\n",
    "        continue\n",
    "\n",
    "    scenes_by_orbit = split_by_orbits(scenes)\n",
    "    all_orbits_bands = []\n",
    "    for orbit, scenes in scenes_by_orbit.items():\n",
    "        items_filtered = sort_by_clouds(row, scenes)\n",
    "        items_filtered = items_filtered[:20]\n",
    "        # break\n",
    "        items_with_tide = filter_by_tide(centroid, items_filtered, limit=8)\n",
    "        bands, profile = downlaod_bands(items_with_tide, time_steps)\n",
    "        all_orbits_bands.append(bands)\n",
    "\n",
    "    all_orbits_bands = np.array(all_orbits_bands)\n",
    "    all_orbits_bands = np.moveaxis(all_orbits_bands, 0, 1)\n",
    "\n",
    "    merged_bands = []\n",
    "    for multi_orbit_bands in all_orbits_bands:\n",
    "        target_array = np.zeros(multi_orbit_bands.shape[1:])\n",
    "        for band in multi_orbit_bands:\n",
    "            target_array[target_array == 0] = band[target_array == 0]\n",
    "        merged_bands.append(target_array)\n",
    "    # merged_bands = np.array(merged_bands)\n",
    "\n",
    "    if len(merged_bands) == target_bands:\n",
    "        export_tif(merged_bands, profile, export_path)\n",
    "    else:\n",
    "        print(f\"Failed to download {row.Name}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
